{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selenium- 사람이 검색용으로 html받아옴 ,urlopen(url)웹페이지 검색\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<html><body><p>test</p></body></html>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html = \"<p>test</p>\"\n",
    "soup = BeautifulSoup(html,'lxml')\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<html><head></head><body><p>test</p></body></html>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html = \"<p>test</p>\"\n",
    "soup = BeautifulSoup(html,'html5lib')\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p>test</p>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html = \"<p>test</p>\"\n",
    "soup = BeautifulSoup(html,'html.parser')\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "html = \"\"\"\n",
    "<html>\n",
    "<head><title>나의 웹페이지</title></head>\n",
    "<p>test1</p>\n",
    "<p>test2</p>\n",
    "<p>test3</p>\n",
    "</html>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<html><head><title>나의 웹페이지</title></head>\n",
       "<body><p>test1</p>\n",
       "<p>test2</p>\n",
       "<p>test3</p>\n",
       "\n",
       "</body></html>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup = BeautifulSoup(html,'html5lib')\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<body><p>test1</p>\n",
       "<p>test2</p>\n",
       "<p>test3</p>\n",
       "\n",
       "</body>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<head><title>나의 웹페이지</title></head>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p>test2</p>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all(\"p\")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "html=\"\"\"\n",
    "<html>\n",
    "<head><title>test site</title></head>\n",
    "<p class='class1' align=\"left\">test3</p>\n",
    "<p class='class1' >test3</p>\n",
    "<p id='p1'>오늘의 주기주수 1500</p>\n",
    "<span class='class3'>span tag text</span>\n",
    "<p class='class4'>test3</p>\n",
    "</html>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<html>\n",
       "<head><title>test site</title></head>\n",
       "<body><p align=\"left\" class=\"class1\">test3</p>\n",
       "<p class=\"class1\">test3</p>\n",
       "<p id=\"p1\">오늘의 주기주수 1500</p>\n",
       "<span class=\"class3\">span tag text</span>\n",
       "<p class=\"class4\">test3</p>\n",
       "</body></html>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup=BeautifulSoup(html, 'lxml')\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p align=\"left\" class=\"class1\">test3</p>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class': ['class1'], 'align': 'left'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.p.attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p align=\"left\" class=\"class1\">test3</p>,\n",
       " <p class=\"class1\">test3</p>,\n",
       " <p id=\"p1\">오늘의 주기주수 1500</p>,\n",
       " <p class=\"class4\">test3</p>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all(\"p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<span class=\"class3\">span tag text</span>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all(\"span\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<head><title>test site</title></head>]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all(\"head\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    " * ESC + M : 마크다운 셀 만들기\n",
    " * ESC + Y : 소스코드 실행 셀 만들기\n",
    " * ESC + A : 위에 셀 추가\n",
    " * ESC + B : 아래 셀 추가\n",
    " * ESC + X : 셀 삭제\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# class이름으로 요소 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p align=\"left\" class=\"class1\">test3</p>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find(\"p\", class_=\"class1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## id 이름으로 요소 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p id=\"p1\">오늘의 주기주수 1500</p>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find(\"p\", id=\"p1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### find \n",
    "    * find_all :리스트\n",
    "    * find : 문자열"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<head><title>test site</title></head>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1=soup.find(\"head\")\n",
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<title>test site</title>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2=soup.find(\"title\")\n",
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test site'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "html=\"\"\"\n",
    "<html>\n",
    "<head>\n",
    "    <title>test site</title>\n",
    "</head>\n",
    "<body>\n",
    "    <div>\n",
    "        <p class='class1' align=\"left\">test3</p>\n",
    "        <p class='class1' >test3</p>\n",
    "    </div>\n",
    "    <div>\n",
    "        <p id='p1'>오늘의 주기주수 1500</p>\n",
    "        <p class='class4'>test3</p>\n",
    "        <span class='class3'>span tag text</span>\n",
    "    </div>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "soup=BeautifulSoup(html,'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3=soup.find(\"div\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p align=\"left\" class=\"class1\">test3</p>,\n",
       " <p class=\"class1\">test3</p>,\n",
       " <p id=\"p1\">오늘의 주기주수 1500</p>,\n",
       " <p class=\"class4\">test3</p>]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2=soup.find_all(\"p\")\n",
    "data2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 요소안 list사용해서 특정 element가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup2=soup.find_all(\"div\")[0].find_all(\"p\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p align=\"left\" class=\"class1\">test3</p>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = '''\n",
    "<html>\n",
    "<head>\n",
    "    <title> test site </title>\n",
    "</head>\n",
    "<body>\n",
    "    <a href=\"https://www.google.com\">구글</a>\n",
    "    <div>\n",
    "        <p class='class1' align=\"left\">test3</p>\n",
    "        <p class='class1'>test2</p>\n",
    "    </div>\n",
    "    <div>\n",
    "        <p id='p1'>오늘의 주가지수 1500</p>\n",
    "        <p class='class4'>test3</p>\n",
    "        <span class='class3'>span tag text</span>\n",
    "        <a href=\"https://www.naver.com/\">네이버</a>\n",
    "        <a href=\"https://www.daum.com/\">다음</a>\n",
    "    </div>\n",
    "</body>\n",
    "</html>\n",
    "'''\n",
    "soup = BeautifulSoup(html, 'lxml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-2 (생각해보기) a태그의 모든 url을 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup2=soup.find_all(\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "ResultSet object has no attribute 'a'. You're probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-85bbba08e8f4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msoup2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\bs4\\element.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2171\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2172\u001b[0m         \u001b[1;34m\"\"\"Raise a helpful exception to explain a common code fix.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2173\u001b[1;33m         raise AttributeError(\n\u001b[0m\u001b[0;32m   2174\u001b[0m             \u001b[1;34m\"ResultSet object has no attribute '%s'. You're probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2175\u001b[0m         )\n",
      "\u001b[1;31mAttributeError\u001b[0m: ResultSet object has no attribute 'a'. You're probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?"
     ]
    }
   ],
   "source": [
    "soup2.a.string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.google.com'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.a.get('href')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(soup.a.get('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.google.com'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.a.attrs['href']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<list_iterator at 0x2196402e580>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1=soup.find_all(\"div\")[1]\n",
    "a1.children\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "a2=list(a1.children)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1=soup.find_all(\"div\")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "a2=list(a1.children)[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<span class=\"class3\">span tag text</span>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<span class=\"class3\">span tag text</span>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(soup.find_all(\"div\")[1].children)[5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<span class=\"class3\">span tag text</span>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(soup.find_all(\"div\")[1].findChildren())[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<span class=\"class3\">span tag text</span>]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " soup.find_all(\"div\")[1].findChildren(\"span\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "span tag text\n"
     ]
    }
   ],
   "source": [
    "s= soup.find_all(\"div\")[1].findChildren(\"span\")[0]\n",
    "print(s.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_all = soup.find(\"body\").find_all(\"a\")\n",
    "p_all1=soup.findChildren(\"a\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "구글 https://www.google.com\n",
      "네이버 https://www.naver.com/\n",
      "다음 https://www.daum.com/\n"
     ]
    }
   ],
   "source": [
    "for one in p_all:\n",
    "        print(one.text,one.get(\"href\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSV 파일로 만들어 보기!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "구글 https://www.google.com\n",
      "네이버 https://www.naver.com/\n",
      "다음 https://www.daum.com/\n",
      "['구글', '네이버', '다음']\n",
      "['https://www.google.com', 'https://www.naver.com/', 'https://www.daum.com/']\n"
     ]
    }
   ],
   "source": [
    "com =[]\n",
    "urls=[]\n",
    "\n",
    "list_a=soup.findAll(\"a\")\n",
    "for one in list_a:\n",
    "    print(one.text, one.get(\"href\"))\n",
    "    com.append(one.text)\n",
    "    urls.append(one.get('href'))\n",
    "print(com)\n",
    "print(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pandas의 기본 자료형\n",
    "    *Series\n",
    "    *DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>회사명</th>\n",
       "      <th>웹사이트</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>구글</td>\n",
       "      <td>https://www.google.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>네이버</td>\n",
       "      <td>https://www.naver.com/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>다음</td>\n",
       "      <td>https://www.daum.com/</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   회사명                    웹사이트\n",
       "0   구글  https://www.google.com\n",
       "1  네이버  https://www.naver.com/\n",
       "2   다음   https://www.daum.com/"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat={'회사명':com, '웹사이트':urls }\n",
    "dat=pd.DataFrame(dat)\n",
    "# dat=pd.Series(dat)\n",
    "dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steam\n",
      "['.android', '.astropy', '.cordova', '.dotnet', '.eclipse', '.gitconfig', '.idlerc', '.ipynb_checkpoints', '.ipython', '.jupyter', '.matplotlib', '.p2', '.PyCharm2019.1', '.PyCharmCE2017.3', '.python_history', '.tooling', '.vscode', '06_16.ipynb', '3D Objects', 'anaconda3', 'ansel', 'AppData', 'Application Data', 'Autodesk', 'Contacts', 'Cookies', 'Desktop', 'Documents', 'Downloads', 'eclipse', 'eclipse-workspace', 'Favorites', 'Helloworld.class', 'helloworld.java', 'IntelGraphicsProfiles', 'Links', 'Local Settings', 'MicrosoftEdgeBackups', 'Music', 'My Documents', 'NetHood', 'NTUSER.DAT', 'ntuser.dat.LOG1', 'ntuser.dat.LOG2', 'NTUSER.DAT{8cb29cae-c225-11eb-b8cd-df9568592192}.TM.blf', 'NTUSER.DAT{8cb29cae-c225-11eb-b8cd-df9568592192}.TMContainer00000000000000000001.regtrans-ms', 'NTUSER.DAT{8cb29cae-c225-11eb-b8cd-df9568592192}.TMContainer00000000000000000002.regtrans-ms', 'ntuser.ini', 'OneDrive', 'Pictures', 'PrintHood', 'PycharmProjects', 'Recent', 'Roaming', 'Saved Games', 'seaborn-data', 'Searches', 'SendTo', 'source', 'Templates', 'Untitled.ipynb', 'Videos', '시작 메뉴', '회사면과웹사이트.csv', '회사면과웹사이트.xlsx']\n"
     ]
    }
   ],
   "source": [
    "# dat.to_csv(\"회사면과웹사이트.csv\", index = False)\n",
    "dat.to_excel(\"회사면과웹사이트.xlsx\", index = False)\n",
    "#확인\n",
    "import os\n",
    "print(os.getcwd())\n",
    "print(os.listdir(os.getcwd()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<title>나의 웹 페이지</title>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "url = \"https://ldjwj.github.io/00_PYTHON_LEVELUP_CLASS/web_class/index.html \"\n",
    "page = urlopen(url)\n",
    "page\n",
    "soup = BeautifulSoup(page, \"html.parser\")\n",
    "soup.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<title>국내증시 : 네이버 금융</title>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "url = \"https://finance.naver.com/sise/ \"\n",
    "page = urlopen(url)\n",
    "page\n",
    "soup = BeautifulSoup(page, \"html.parser\")\n",
    "soup.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kospi: 3,278.31\n",
      "kosdaq: 999.54\n",
      "kospi200: 436.86\n"
     ]
    }
   ],
   "source": [
    "kos=soup.find(\"span\", id=\"KOSPI_now\")\n",
    "kod=soup.find(\"span\", id=\"KOSDAQ_now\")\n",
    "k200=soup.find(\"span\", id=\"KPI200_now\")\n",
    "print(\"kospi: \"+kos.string)\n",
    "print(\"kosdaq: \"+kod.string)\n",
    "print(\"kospi200: \"+k200.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<li><em>1.</em><a href=\"/item/main.nhn?code=035420\" onclick=\"clickcr(this,'boa.list','035420','1',event)\">NAVER</a><span class=\"up\">394,000</span><em class=\"bu_p bu_pup\"><span class=\"blind\">상승</span></em></li>"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hoo=soup.find('ul', id=\"popularItemList\")\n",
    "hah =hoo.find_all(\"li\")\n",
    "hah[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "nah=[]\n",
    "price_=[]\n",
    "for one in hah:\n",
    "    com_one=one.find(\"a\").text\n",
    "    price_one=one.find(\"span\").text\n",
    "    nah.append(com_one)\n",
    "    price_.append(price_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NAVER', '삼성전자', '두산중공업', '카카오', '대원전선', '가비아', 'HMM', '대한전선', '서울식품', '한전산업']\n",
      "['394,000', '81,600', '24,700', '143,500', '3,570', '19,100', '45,450', '3,300', '470', '10,850']\n"
     ]
    }
   ],
   "source": [
    "print(nah)\n",
    "print(price_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1위. NAVER (상승)\n",
      "2위. 삼성전자 (상승)\n",
      "3위. 두산중공업 (상승)\n",
      "4위. 카카오 (상승)\n",
      "5위. 대원전선 (상승)\n",
      "6위. 가비아 (상승)\n",
      "7위. HMM (상승)\n",
      "8위. 대한전선 (상승)\n",
      "9위. 서울식품 (상승)\n",
      "0위. 한전산업 (상승)\n"
     ]
    }
   ],
   "source": [
    "ul = soup.find_all(\"ul\", class_=\"lst_pop\", id=\"popularItemList\")[0]\n",
    "gl = soup.find_all(\"ul\", class_=\"lst_pop\", id=\"popularItemList\")[0].find_all('span')\n",
    "ranktag = ul.find_all(\"a\")\n",
    "for one in ranktag :\n",
    "    print(one.get(\"onclick\")[-9]+\"위. \"+one.text+\" (\" +gl.text+\")\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<span class=\"blind\">상승</span>\n"
     ]
    }
   ],
   "source": [
    "ul = soup.find_all(\"ul\", class_=\"lst_pop\", id=\"popularItemList\")[0].find_all('span')[1]\n",
    "print(ul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1.NAVER394,000상승\n",
      "2.삼성전자81,600상승\n",
      "3.두산중공업24,700상승\n",
      "4.카카오143,500하락\n",
      "5.대원전선3,570상승\n",
      "6.가비아19,100상한가\n",
      "7.HMM45,450상승\n",
      "8.대한전선3,300상승\n",
      "9.서울식품470상승\n",
      "10.한전산업10,850상승\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ul_=soup.findAll('ul',class_='lst_pop', id=\"popularItemList\")\n",
    "for x in ul_:\n",
    "    print(x.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<span class=\"blind\">상승</span>"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://finance.naver.com/sise/'\n",
    "page = urlopen(url)\n",
    "soup = BeautifulSoup(page, 'html.parser')\n",
    "ul = soup.find_all(\"ul\", class_=\"lst_pop\", id=\"popularItemList\")[0]\n",
    "ranktag = ul.find_all(\"a\")\n",
    "updowntag = ul.find_all(\"span\", class_=\"blind\")\n",
    "# for i in range(10) :\n",
    "#     rank = ranktag[i]\n",
    "#     updown = updowntag[i]\n",
    "#     print(rank.get(\"onclick\")[-9]+\"위. \"+rank.text+\":\"+rank.get(\"onclick\")[-18:-12]+\"\\t\"+updown.text)\n",
    "#     #onclick 안에는 순위 종목코드 있다!\n",
    "updowntag[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>주식명</th>\n",
       "      <th>종목코드</th>\n",
       "      <th>상승&amp;하락</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>삼성전자</td>\n",
       "      <td>005930</td>\n",
       "      <td>상승</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>쌍방울</td>\n",
       "      <td>102280</td>\n",
       "      <td>하락</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>한전산업</td>\n",
       "      <td>130660</td>\n",
       "      <td>상한가</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HMM</td>\n",
       "      <td>011200</td>\n",
       "      <td>상승</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>카카오</td>\n",
       "      <td>035720</td>\n",
       "      <td>하락</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LG화학</td>\n",
       "      <td>051910</td>\n",
       "      <td>하락</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>한국전력</td>\n",
       "      <td>015760</td>\n",
       "      <td>상승</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>대원전선</td>\n",
       "      <td>006340</td>\n",
       "      <td>상승</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>가비아</td>\n",
       "      <td>079940</td>\n",
       "      <td>상한가</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LG전자</td>\n",
       "      <td>66570'</td>\n",
       "      <td>하락</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    주식명    종목코드 상승&하락\n",
       "0  삼성전자  005930    상승\n",
       "1   쌍방울  102280    하락\n",
       "2  한전산업  130660   상한가\n",
       "3   HMM  011200    상승\n",
       "4   카카오  035720    하락\n",
       "5  LG화학  051910    하락\n",
       "6  한국전력  015760    상승\n",
       "7  대원전선  006340    상승\n",
       "8   가비아  079940   상한가\n",
       "9  LG전자  66570'    하락"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "url = 'https://finance.naver.com/sise/'\n",
    "page = urlopen(url)\n",
    "soup = BeautifulSoup(page, 'html.parser')\n",
    "ul = soup.find_all(\"ul\", class_=\"lst_pop\", id=\"popularItemList\")[0]\n",
    "ranktag = ul.find_all(\"a\")\n",
    "updowntag = ul.find_all(\"span\", class_=\"blind\")\n",
    "ps_cod=[]\n",
    "ps_nam=[]\n",
    "ps_ud=[]\n",
    "\n",
    "for i in range(10) :\n",
    "    rank = ranktag[i] # 종목이름&코드 보유\n",
    "    updown = updowntag[i] #상승&하락 보유\n",
    "#     print(str(i+1)+\"위. \"+rank.text+\"(\"+rank.get(\"onclick\")[-18:-12]+\") = \"+updown.text)\n",
    "    ps_cod.append(rank.get(\"onclick\")[-18:-12]) #종목코드\n",
    "    ps_nam.append(rank.text) #이름\n",
    "    ps_ud.append(updown.text) #상하락\n",
    "\n",
    "    #onclick 안에는 순위 종목코드 있다!\n",
    "\n",
    "ul1 = soup.find_all(\"ul\", class_=\"lst_major\")[0]\n",
    "ranktag1 = ul1.find_all(\"a\")\n",
    "num_da = ul1.find_all(\"span\")\n",
    "ps_num=[]#지수수치\n",
    "ps_name=[]#이름\n",
    "ps_ude=[]#상하락\n",
    "\n",
    "for i in range(5) :\n",
    "    rank1 = ranktag1[i] # 해외지수 이름 보유\n",
    "    dan1 = num_da [i*2] # 해외지수 수치 보유 \n",
    "    dan2 = num_da [i*2+1] # 상승&하락 보유\n",
    "#     print(rank1.text+\":\"+dan1.text+\"\\t\"+dan2.text)\n",
    "    ps_num.append(dan1.text) #지수수치\n",
    "    ps_name.append(rank1.text) #이름\n",
    "    ps_ude.append(dan2.text) #상하락\n",
    "\n",
    "dat = { '주식명':ps_nam,'종목코드':ps_cod ,'상승&하락':ps_ud }\n",
    "dat = pd.DataFrame(dat)\n",
    "dat.to_excel(\"주식인기검색 종목.xlsx\", index=False)\n",
    "dat\n",
    "\n",
    "# dat_a = { '지수명':ps_name,'지수수치':ps_num ,'상승&하락':ps_ude }\n",
    "# dat_a = pd.DataFrame(dat_a)\n",
    "# dat_a\n",
    "# dat_a.to_excel(\"해외지수.xlsx\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
